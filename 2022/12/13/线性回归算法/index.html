<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    <meta name="description" content="Hexo Theme Redefine">
    <meta name="author" content="chen">
    
    <title>
        
            线性回归算法 |
        
        Chen&#39;s blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    
<link rel="stylesheet" href="/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/css/v5-font-face.min.css">

    
<link rel="stylesheet" href="/css/duotone.min.css">

    
<link rel="stylesheet" href="/css/brands.min.css">

    
<link rel="stylesheet" href="/css/solid.min.css">

    
<link rel="stylesheet" href="/css/css2.css">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <script id="hexo-configurations">
    let REDEFINE = window.REDEFINE || {};
    REDEFINE.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.xml"};
    REDEFINE.theme_config = {"toc":{"enable":true,"number":false,"expand_all":true,"init_open":true},"style":{"primary_color":"#005080","avatar":"/images/avatar.svg","favicon":"/images/logo.svg","article_img_align":"center","right_side_width":"210px","content_max_width":"1000px","nav_color":{"left":"#f78736","right":"#367df7","transparency":35},"hover":{"shadow":true,"scale":false},"first_screen":{"enable":true,"background_image":{"light":"https://evan.beee.top/img/wallhaven-wqery6-light.webp","dark":"https://evan.beee.top/img/wallhaven-wqery6-dark.webp"},"title_color":{"light":"#fff","dark":"#d1d1b6"},"description":"Chen's blog"},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true},"pjax":{"enable":true},"lazyload":{"enable":true},"version":"0.3.5"};
    REDEFINE.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">
    
    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                Chen&#39;s blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">
            <div class="article-title">
                <span class="title-hover-animation"><h1 style="font-size:2rem; font-weight: bold; margin: 10px 0;">线性回归算法</h1></span>
            </div>

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/avatar.svg">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">chen</span>
                            
                                <span class="author-label">lol</span>
                            
                        </div>
                        <div class="meta-info">
                            <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-duotone fa-pen-line"></i>&nbsp;
        <span class="pc">2022-12-13 20:38:52</span>
        <span class="mobile">2022-12-13 20:38</span>
    </span>
    
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content markdown-body">
                <h1 id="1-线性回归算法简介"><a href="#1-线性回归算法简介" class="headerlink" title="1.线性回归算法简介"></a>1.线性回归算法简介</h1><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-28f661e8edd149d6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="1"
                ></p>
<p>线性回归算法以一个坐标系里一个维度为结果，其他维度为特征（如二维平面坐标系中横轴为特征，纵轴为结果），无数的训练集放在坐标系中，发现他们是围绕着一条执行分布。线性回归算法的期望，就是寻找一条直线，最大程度的“拟合”样本特征和样本输出标记的关系<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-ed83e4dab6237239.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="2"
                ></p>
<h5 id="样本特征只有一个的线性回归问题，为简单线性回归，如房屋价格-房屋面积"><a href="#样本特征只有一个的线性回归问题，为简单线性回归，如房屋价格-房屋面积" class="headerlink" title="样本特征只有一个的线性回归问题，为简单线性回归，如房屋价格-房屋面积"></a>样本特征只有一个的线性回归问题，为简单线性回归，如房屋价格-房屋面积</h5><p>将横坐标作为x轴，纵坐标作为y轴，每一个点为（X(i) ,y(i)）,那么我们期望寻找的直线就是y&#x3D;ax+b，当给出一个新的点x(j)的时候，我们希望预测的y^(j)&#x3D;ax(j)+b</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-9907accb4deda2e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="7"
                ></p>
<ul>
<li>不使用直接相减的方式，由于差值有正有负，会抵消</li>
<li>不适用绝对值的方式，由于绝对值函数存在不可导的点<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-674c2856a8eb6ccb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="8"
                ></li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-a5b3ed8589e06778.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="11"
                ></p>
<h5 id="通过上面的推导，我们可以归纳出一类机器学习算法的基本思路，如下图；其中损失函数是计算期望值和预测值的差值，期望其差值（也就是损失）越来越小，而效用函数则是描述拟合度，期望契合度越来越好"><a href="#通过上面的推导，我们可以归纳出一类机器学习算法的基本思路，如下图；其中损失函数是计算期望值和预测值的差值，期望其差值（也就是损失）越来越小，而效用函数则是描述拟合度，期望契合度越来越好" class="headerlink" title="通过上面的推导，我们可以归纳出一类机器学习算法的基本思路，如下图；其中损失函数是计算期望值和预测值的差值，期望其差值（也就是损失）越来越小，而效用函数则是描述拟合度，期望契合度越来越好"></a>通过上面的推导，我们可以归纳出一类机器学习算法的基本思路，如下图；其中损失函数是计算期望值和预测值的差值，期望其差值（也就是损失）越来越小，而效用函数则是描述拟合度，期望契合度越来越好</h5><h2 id=""><a href="#" class="headerlink" title=""></a><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-4d9f03a1442afd3b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="9"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-13cf3c2d50fbb1f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="10"
                ></h2><h1 id="2-简单线性回归的实现"><a href="#2-简单线性回归的实现" class="headerlink" title="2.简单线性回归的实现"></a>2.简单线性回归的实现</h1><h2 id="2-1-for循环方式实现"><a href="#2-1-for循环方式实现" class="headerlink" title="2.1 for循环方式实现"></a>2.1 for循环方式实现</h2><ul>
<li><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2></li>
</ul>
<h3 id="a-b公式"><a href="#a-b公式" class="headerlink" title="a,b公式"></a>a,b公式</h3><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-d6a7d9184027fd0e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="2.2-2"
                ></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">class SimpleLinearRegression1:</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        &quot;&quot;&quot;初始化Simple Linear Regression 模型&quot;&quot;&quot;</span><br><span class="line">        self.a_ = None</span><br><span class="line">        self.b_ = None</span><br><span class="line"></span><br><span class="line">    def fit(self, x_train, y_train):</span><br><span class="line">        &quot;&quot;&quot;根据训练集x_train，y_train 训练Simple Linear Regression 模型&quot;&quot;&quot;</span><br><span class="line">        assert x_train.ndim == 1,\</span><br><span class="line">            &quot;Simple Linear Regression can only solve simple feature training data&quot;</span><br><span class="line">        assert len(x_train) == len(y_train),\</span><br><span class="line">            &quot;the size of x_train must be equal to the size of y_train&quot;</span><br><span class="line"></span><br><span class="line">        # 求均值</span><br><span class="line">        x_mean = x_train.mean()</span><br><span class="line">        y_mean = y_train.mean()</span><br><span class="line"></span><br><span class="line">        # 分子</span><br><span class="line">        num = 0.0</span><br><span class="line">        # 分母</span><br><span class="line">        d = 0.0</span><br><span class="line"></span><br><span class="line">        # 计算分子分母</span><br><span class="line">        for x_i, y_i in zip(x_train, y_train):</span><br><span class="line">            num += (x_i-x_mean)*(y_i-y_mean)</span><br><span class="line">            d += (x_i-x_mean) ** 2</span><br><span class="line"></span><br><span class="line">        # 计算参数a和b</span><br><span class="line">        self.a_ = num/d</span><br><span class="line">        self.b_ = y_mean - self.a_ * x_mean</span><br><span class="line"></span><br><span class="line">        return self</span><br><span class="line"></span><br><span class="line">    def predict(self, x_predict):</span><br><span class="line">        &quot;&quot;&quot;给定待预测集x_predict，返回x_predict对应的预测结果值&quot;&quot;&quot;</span><br><span class="line">        assert x_predict.ndim == 1,\</span><br><span class="line">            &quot;Simple Linear Regression can only solve simple feature training data&quot;</span><br><span class="line">        assert self.a_ is not None and self.b_ is not None,\</span><br><span class="line">            &quot;must fit before predict!&quot;</span><br><span class="line"></span><br><span class="line">        return np.array([self._predict(x) for x in x_predict])</span><br><span class="line"></span><br><span class="line">    def _predict(self, x_single):</span><br><span class="line">        &quot;&quot;&quot;给定单个待预测数据x_single，返回x_single对应的预测结果值&quot;&quot;&quot;</span><br><span class="line">        return self.a_*x_single+self.b_</span><br><span class="line"></span><br><span class="line">    def __repr__(self):</span><br><span class="line">        return &quot;SimpleLinearRegression1()&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>
<ul>
<li><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2></li>
</ul>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure></div>

<h3 id="简单自定义一个训练集并描绘"><a href="#简单自定义一个训练集并描绘" class="headerlink" title="简单自定义一个训练集并描绘"></a>简单自定义一个训练集并描绘</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = np.array([<span class="number">1.</span>,<span class="number">2.</span>,<span class="number">3.</span>,<span class="number">4.</span>,<span class="number">5.</span>])</span><br><span class="line">y = np.array([<span class="number">1.</span>,<span class="number">3.</span>,<span class="number">2.</span>,<span class="number">3.</span>,<span class="number">5.</span>])</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.axis([<span class="number">0</span>,<span class="number">6</span>,<span class="number">0</span>,<span class="number">6</span>])</span><br></pre></td></tr></table></figure></div>




<pre><code>[0, 6, 0, 6]
</code></pre>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-ef43bf85ec0b3298.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="2.1-1"
                ></p>
<h3 id="使用我们自己的SimpleLinearRegression1"><a href="#使用我们自己的SimpleLinearRegression1" class="headerlink" title="使用我们自己的SimpleLinearRegression1"></a>使用我们自己的SimpleLinearRegression1</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> machine_learning.SimpleLinearRegression1 <span class="keyword">import</span> SimpleLinearRegression1</span><br><span class="line"></span><br><span class="line">reg1 = SimpleLinearRegression1()</span><br><span class="line">reg1.fit(x,y)</span><br><span class="line"><span class="comment"># 输出  SimpleLinearRegression1()</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y_predict = reg1.predict(np.array([<span class="number">6.</span>]))</span><br><span class="line">y_predict</span><br><span class="line"><span class="comment">#   输出  array([5.2])</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reg1.a_</span><br><span class="line"> <span class="comment">#  0.8</span></span><br><span class="line">reg1.b_</span><br><span class="line"><span class="comment">#     0.39999999999999947</span></span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y_hat = reg1.predict(x)</span><br><span class="line">plt.scatter(x,y)</span><br><span class="line">plt.plot(x,y_hat,color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.axis([<span class="number">0</span>,<span class="number">6</span>,<span class="number">0</span>,<span class="number">6</span>])</span><br></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-2f448da2a1a38cf8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="2.2-2"
                ></p>
<h2 id="2-2-向量化"><a href="#2-2-向量化" class="headerlink" title="2.2 向量化"></a>2.2 向量化</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-6abe87c3160fd366.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="2.2-1"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-215060bbf7fc403b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="2.2-2"
                ></p>
<h3 id="向量化改进num-d的计算方法"><a href="#向量化改进num-d的计算方法" class="headerlink" title="向量化改进num,d的计算方法"></a>向量化改进num,d的计算方法</h3><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 使用向量化点乘计算分子和分母</span><br><span class="line">num = (x_train-x_mean).dot(y_train-y_mean)</span><br><span class="line">d = (x_train-x_mean).dot(x_train-x_mean)</span><br></pre></td></tr></table></figure></div>
<h3 id="向量化实现的性能测试"><a href="#向量化实现的性能测试" class="headerlink" title="向量化实现的性能测试"></a>向量化实现的性能测试</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m = <span class="number">1000000</span></span><br><span class="line">big_x = np.random.random(size=m)</span><br><span class="line">big_y = big_x * <span class="number">2.0</span> + <span class="number">3.0</span> + np.random.normal(size=m)</span><br></pre></td></tr></table></figure></div>


<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%timeit reg1.fit(big_x,big_y)</span><br><span class="line">%timeit reg2.fit(big_x,big_y)</span><br></pre></td></tr></table></figure></div>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 输出</span><br><span class="line">826 ms ± 6.93 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</span><br><span class="line">11.3 ms ± 84.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</span><br></pre></td></tr></table></figure></div>
<p>可以看出，向量化的运行速度比循环的形式速度要快80倍</p>
<h1 id="3-衡量线性回归算法的指标"><a href="#3-衡量线性回归算法的指标" class="headerlink" title="3.衡量线性回归算法的指标"></a>3.衡量线性回归算法的指标</h1><h2 id="3-1-衡量标准"><a href="#3-1-衡量标准" class="headerlink" title="3.1 衡量标准"></a>3.1 衡量标准</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-c440c129cd28b499.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="3.1"
                ><br>其中衡量标准是和m有关的，因为越多的数据量产生的误差和可能会更大，但是毫无疑问越多的数据量训练出来的模型更好，为此需要一个取消误差的方法，如下</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-31090a2f956341f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="3.2"
                ><br>MSE 的缺点，量纲不准确，如果y的单位是万元，平方后就变成了万元的平方，这可能会给我们带来一些麻烦<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-250c94798e4c458c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="3.3"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-ace4bb2857d3417f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="3.4"
                ><br>RMSE 平方累加后再开根号，如果某些预测结果和真实结果相差非常大，那么RMSE的结果会相对变大，所以RMSE有放大误差的趋势，而MAE没有，他直接就反应的是预测结果和真实结果直接的差距，正因如此，从某种程度上来说，想办法我们让RMSE变的更小小对于我们来说比较有意义，因为这意味着整个样本的错误中，那个最值相对比较小，而且我们之前训练样本的目标，就是RMSE根号里面1&#x2F;m的这一部分，而这一部分的本质和优化RMSE是一样的</p>
<h2 id="3-2-MSE-RMSE-MAE的实现"><a href="#3-2-MSE-RMSE-MAE的实现" class="headerlink" title="3.2 MSE,RMSE,MAE的实现"></a>3.2 MSE,RMSE,MAE的实现</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def mean_squared_error(y_true, y_predict):</span><br><span class="line">    &quot;&quot;&quot;计算y_true和y_predict之间的MSE&quot;&quot;&quot;</span><br><span class="line">    assert len(y_true) == len(y_predict), \</span><br><span class="line">        &quot;the size of y_true must be equal to the size of y_predict&quot;</span><br><span class="line"></span><br><span class="line">    return np.sum((y_true - y_predict)**2) / len(y_true)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def root_mean_squared_error(y_true, y_predict):</span><br><span class="line">    &quot;&quot;&quot;计算y_true和y_predict之间的RMSE&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    return sqrt(mean_squared_error(y_true, y_predict))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def mean_absolute_error(y_true, y_predict):</span><br><span class="line">    &quot;&quot;&quot;计算y_true和y_predict之间的RMSE&quot;&quot;&quot;</span><br><span class="line">    assert len(y_true) == len(y_predict), \</span><br><span class="line">        &quot;the size of y_true must be equal to the size of y_predict&quot;</span><br><span class="line"></span><br><span class="line">    return np.sum(np.absolute(y_true - y_predict)) / len(y_true)</span><br></pre></td></tr></table></figure></div>
<h2 id="3-3-调用sikit-learn-的实现"><a href="#3-3-调用sikit-learn-的实现" class="headerlink" title="3.3 调用sikit learn 的实现"></a>3.3 调用sikit learn 的实现</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import mean_squared_error</span><br><span class="line">from sklearn.metrics import mean_absolute_error</span><br><span class="line">mean_squared_error(y_test,y_predict)</span><br></pre></td></tr></table></figure></div>



<h1 id="4-最好的衡量线性回归法的指标-R-Squared"><a href="#4-最好的衡量线性回归法的指标-R-Squared" class="headerlink" title="4.最好的衡量线性回归法的指标 R Squared"></a>4.最好的衡量线性回归法的指标 R Squared</h1><h3 id="RMSE-和-MAE的局限性"><a href="#RMSE-和-MAE的局限性" class="headerlink" title="RMSE 和 MAE的局限性"></a>RMSE 和 MAE的局限性</h3><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-879bb4bcbb132790.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="4.1"
                ><br>可能预测房源准确度，RMSE或者MAE的值为5，预测学生的分数，结果的误差是10，这个5和10没有判断性，因为5和10对应不同的单位和量纲，无法比较</p>
<h2 id="4-1-解决办法-R-Squared简介"><a href="#4-1-解决办法-R-Squared简介" class="headerlink" title="4.1 解决办法-R Squared简介"></a>4.1 解决办法-R Squared简介</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-9c44823246ca9510.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="4.1-1"
                ></p>
<h3 id="4-1-1-R-Squared-意义"><a href="#4-1-1-R-Squared-意义" class="headerlink" title="4.1.1 R Squared 意义"></a>4.1.1 R Squared 意义</h3><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-c45d712c01b512f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="4.1-2"
                ><br>使用BaseLine Model产生的错误会很大，使用我们的模型预测产生的错误会相对少些（因为我们的模型充分的考虑了y和x之间的关系），用这两者相减，结果就是拟合了我们的错误指标，用1减去这个商结果就是我们的模型没有产生错误的指标<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-a2bab126bfe18889.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="4.1-3"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-670dd67010cada04.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="4.1-4"
                ></p>
<h3 id="4-1-2-实现"><a href="#4-1-2-实现" class="headerlink" title="4.1.2 实现"></a>4.1.2 实现</h3><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def r2_score(y_true, y_predict):</span><br><span class="line">    &quot;&quot;&quot;计算y_true和y_predict之间的R Square&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    return 1 - mean_squared_error(y_true, y_predict)/np.var(y_true)</span><br></pre></td></tr></table></figure></div>
<p>sikit learn</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import r2_score</span><br><span class="line">r2_score(y_test,y_predict)</span><br></pre></td></tr></table></figure></div>
<p>将计算分数方法封装到我们的SimpleLinearRegression中</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from .metrics import r2_score</span><br><span class="line">def score(self, x_test, y_test):</span><br><span class="line">        &quot;&quot;&quot;根据测试数据集 x_test 和 y_test 确定当前模型的准确度&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">        y_predict = self.predict(x_test)</span><br><span class="line">        return r2_score(y_test, y_predict)</span><br></pre></td></tr></table></figure></div>



<h1 id="5-多元线性回归"><a href="#5-多元线性回归" class="headerlink" title="5.多元线性回归"></a>5.多元线性回归</h1><h2 id="5-1-多元线性回归简介和正规方程解"><a href="#5-1-多元线性回归简介和正规方程解" class="headerlink" title="5.1 多元线性回归简介和正规方程解"></a>5.1 多元线性回归简介和正规方程解</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-b47942551895e623.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="5.1-1"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-99d5435ff88ae007.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="5.1-2"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-7dd16d69786c892a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="5.1-3"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-bc789f7481a29101.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="5.1-4"
                ></p>
<p>补充（矩阵点乘：A（m行）·B（n列） &#x3D; A的每一行与B的每一列相乘再相加，等到结果是m行n列的）<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-1e6d562cb4d08ac3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="5.1-5"
                ><br>补充（一个1xm的行向量乘以一个mx1的列向量等于一个数）<br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-eaded0b058dae228.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="5.1-6"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-4faa4437792aaa7e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="5.1-7"
                ><br>推导过程参考 <a class="link"   target="_blank" rel="noopener" href="https://blog.csdn.net/nomadlx53/article/details/50849941" >https://blog.csdn.net/nomadlx53/article/details/50849941<i class="fas fa-external-link-alt"></i></a></p>
<h2 id="4-2-多元线性回归实现"><a href="#4-2-多元线性回归实现" class="headerlink" title="4.2 多元线性回归实现"></a>4.2 多元线性回归实现</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-96238af4246f128b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="4.2-1"
                ></p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from .metrics import r2_score</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class LinearRegression:</span><br><span class="line"></span><br><span class="line">    def __init__(self):</span><br><span class="line">        &quot;&quot;&quot;初始化Linear Regression模型&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">        # 系数向量（θ1,θ2,.....θn）</span><br><span class="line">        self.coef_ = None</span><br><span class="line">        # 截距 (θ0)</span><br><span class="line">        self.interception_ = None</span><br><span class="line">        # θ向量</span><br><span class="line">        self._theta = None</span><br><span class="line"></span><br><span class="line">    def fit_normal(self, X_train, y_train):</span><br><span class="line">        &quot;&quot;&quot;根据训练数据集X_train，y_train 训练Linear Regression模型&quot;&quot;&quot;</span><br><span class="line">        assert X_train.shape[0] == y_train.shape[0], \</span><br><span class="line">            &quot;the size of X_train must be equal to the size of y_train&quot;</span><br><span class="line"></span><br><span class="line">        # np.ones((len(X_train), 1)) 构造一个和X_train 同样行数的，只有一列的全是1的矩阵</span><br><span class="line">        # np.hstack 拼接矩阵</span><br><span class="line">        X_b = np.hstack([np.ones((len(X_train), 1)), X_train])</span><br><span class="line">        # X_b.T 获取矩阵的转置</span><br><span class="line">        # np.linalg.inv() 获取矩阵的逆</span><br><span class="line">        # dot() 矩阵点乘</span><br><span class="line">        self._theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)</span><br><span class="line"></span><br><span class="line">        self.interception_ = self._theta[0]</span><br><span class="line">        self.coef_ = self._theta[1:]</span><br><span class="line"></span><br><span class="line">        return self</span><br><span class="line"></span><br><span class="line">    def predict(self, X_predict):</span><br><span class="line">        &quot;&quot;&quot;给定待预测数据集X_predict，返回表示X_predict的结果向量&quot;&quot;&quot;</span><br><span class="line">        assert self.coef_ is not None and self.interception_ is not None,\</span><br><span class="line">            &quot;must fit before predict&quot;</span><br><span class="line">        assert X_predict.shape[1] == len(self.coef_),\</span><br><span class="line">            &quot;the feature number of X_predict must be equal to X_train&quot;</span><br><span class="line"></span><br><span class="line">        X_b = np.hstack([np.ones((len(X_predict), 1)), X_predict])</span><br><span class="line">        return X_b.dot(self._theta)</span><br><span class="line"></span><br><span class="line">    def score(self, X_test, y_test):</span><br><span class="line">        &quot;&quot;&quot;根据测试数据集 X_test 和 y_test 确定当前模型的准确度&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">        y_predict = self.predict(X_test)</span><br><span class="line">        return r2_score(y_test, y_predict)</span><br><span class="line"></span><br><span class="line">    def __repr__(self):</span><br><span class="line">        return &quot;LinearRegression()&quot;</span><br></pre></td></tr></table></figure></div>

<h3 id="预测波士顿房价的测试"><a href="#预测波士顿房价的测试" class="headerlink" title="预测波士顿房价的测试"></a>预测波士顿房价的测试</h3><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plot</span><br><span class="line">from sklearn import datasets</span><br><span class="line"></span><br><span class="line"># 加载波士顿房价数据</span><br><span class="line">boston = datasets.load_boston()</span><br><span class="line">X = boston.data</span><br><span class="line">y = boston.target</span><br><span class="line">X = X[y&lt;50.0]</span><br><span class="line">y = y[y&lt;50.0]</span><br><span class="line"></span><br><span class="line"># 分割训练集和测试集</span><br><span class="line">from machine_learning.module_selection import train_test_split</span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,seed=666)</span><br><span class="line"></span><br><span class="line"># 训练模型</span><br><span class="line">from machine_learning.LinearRegression import LinearRegression</span><br><span class="line">reg = LinearRegression()</span><br><span class="line">reg.fit_normal(X_train,y_train)</span><br><span class="line"># 输出 LinearRegression()</span><br><span class="line"></span><br><span class="line"># 结果</span><br><span class="line">reg.coef_</span><br><span class="line"># 输出 array([-1.18919477e-01,  3.63991462e-02, -3.56494193e-02,  5.66737830e-02,</span><br><span class="line">       -1.16195486e+01,  3.42022185e+00, -2.31470282e-02, -1.19509560e+00,</span><br><span class="line">        2.59339091e-01, -1.40112724e-02, -8.36521175e-01,  7.92283639e-03,</span><br><span class="line">       -3.81966137e-01])</span><br><span class="line"></span><br><span class="line">reg.interception_</span><br><span class="line"># 输出 34.16143549621706</span><br><span class="line"></span><br><span class="line">reg.score(X_test,y_test)</span><br><span class="line"># 输出 0.812980260265849</span><br></pre></td></tr></table></figure></div>
<h2 id="4-3-scikit-learn中的回归问题"><a href="#4-3-scikit-learn中的回归问题" class="headerlink" title="4.3 scikit-learn中的回归问题"></a>4.3 scikit-learn中的回归问题</h2><h3 id="scikit-learn-中的线性回归"><a href="#scikit-learn-中的线性回归" class="headerlink" title="scikit-learn 中的线性回归"></a>scikit-learn 中的线性回归</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=<span class="number">666</span>)</span><br></pre></td></tr></table></figure></div>


<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lin_reg = LinearRegression()</span><br></pre></td></tr></table></figure></div>


<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lin_reg.fit(X_train,y_train)</span><br></pre></td></tr></table></figure></div>




<pre><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
</code></pre>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lin_reg.coef_</span><br></pre></td></tr></table></figure></div>




<pre><code>array([-1.14235739e-01,  3.12783163e-02, -4.30926281e-02, -9.16425531e-02,
       -1.09940036e+01,  3.49155727e+00, -1.40778005e-02, -1.06270960e+00,
        2.45307516e-01, -1.23179738e-02, -8.80618320e-01,  8.43243544e-03,
       -3.99667727e-01])
</code></pre>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 由于训练数据集和测试数据集的分割和我们的稍有不同，所以结果会略有不同</span></span><br><span class="line">lin_reg.intercept_</span><br></pre></td></tr></table></figure></div>




<pre><code>32.64566083965224
</code></pre>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lin_reg.score(X_test,y_test)</span><br></pre></td></tr></table></figure></div>




<pre><code>0.8008916199519077
</code></pre>
<h3 id="kNN-Regressor-实现线性回归"><a href="#kNN-Regressor-实现线性回归" class="headerlink" title="kNN Regressor 实现线性回归"></a>kNN Regressor 实现线性回归</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"></span><br><span class="line">knn_reg = KNeighborsRegressor()</span><br><span class="line">knn_reg.fit(X_train,y_train)</span><br><span class="line">knn_reg.score(X_test,y_test)</span><br></pre></td></tr></table></figure></div>




<pre><code>0.602674505080953
</code></pre>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 网格搜索超参数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line">param_grid = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;weights&quot;</span> : [<span class="string">&quot;uniform&quot;</span>],</span><br><span class="line">        <span class="string">&quot;n_neighbors&quot;</span>:[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">11</span>)]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;weights&quot;</span> : [<span class="string">&quot;distance&quot;</span>],</span><br><span class="line">        <span class="string">&quot;n_neighbors&quot;</span>:[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">11</span>)],</span><br><span class="line">        <span class="string">&quot;p&quot;</span>:[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">6</span>)]</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">knn_reg = KNeighborsRegressor()</span><br><span class="line">grid_search = GridSearchCV(knn_reg,param_grid,n_jobs=-<span class="number">1</span>,verbose=<span class="number">1</span>)</span><br><span class="line">grid_search.fit(X_train,y_train)</span><br></pre></td></tr></table></figure></div>

<pre><code>Fitting 3 folds for each of 60 candidates, totalling 180 fits


[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    0.5s finished





GridSearchCV(cv=None, error_score=&#39;raise&#39;,
       estimator=KNeighborsRegressor(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;,
          metric_params=None, n_jobs=1, n_neighbors=5, p=2,
          weights=&#39;uniform&#39;),
       fit_params=None, iid=True, n_jobs=-1,
       param_grid=[&#123;&#39;weights&#39;: [&#39;uniform&#39;], &#39;n_neighbors&#39;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]&#125;, &#123;&#39;weights&#39;: [&#39;distance&#39;], &#39;n_neighbors&#39;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], &#39;p&#39;: [1, 2, 3, 4, 5]&#125;],
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=&#39;warn&#39;,
       scoring=None, verbose=1)
</code></pre>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grid_search.best_params_</span><br></pre></td></tr></table></figure></div>




<pre><code>&#123;&#39;n_neighbors&#39;: 6, &#39;p&#39;: 1, &#39;weights&#39;: &#39;distance&#39;&#125;
</code></pre>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运用了CV交叉验证的方式</span></span><br><span class="line">grid_search.best_score_</span><br></pre></td></tr></table></figure></div>




<pre><code>0.6060327991735741
</code></pre>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grid_search.best_estimator_.score(X_test,y_test)</span><br></pre></td></tr></table></figure></div>




<pre><code>0.7354244906092771
</code></pre>
<h1 id="6-线性回归的可解性和更多思考"><a href="#6-线性回归的可解性和更多思考" class="headerlink" title="6.线性回归的可解性和更多思考"></a>6.线性回归的可解性和更多思考</h1><h2 id="6-1可解释性"><a href="#6-1可解释性" class="headerlink" title="6.1可解释性"></a>6.1可解释性</h2><div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(X,y)</span><br><span class="line">lin_reg.coef_</span><br><span class="line"># 输出：array([-1.05574295e-01,  3.52748549e-02, -4.35179251e-02,  4.55405227e-01,</span><br><span class="line">       -1.24268073e+01,  3.75411229e+00, -2.36116881e-02, -1.21088069e+00,</span><br><span class="line">        2.50740082e-01, -1.37702943e-02, -8.38888137e-01,  7.93577159e-03,</span><br><span class="line">       -3.50952134e-01])</span><br><span class="line"># 将特征结果坐标排序</span><br><span class="line">np.argsort(lin_reg.coef_)</span><br><span class="line"># 输出：array([ 4,  7, 10, 12,  0,  2,  6,  9, 11,  1,  8,  3,  5])</span><br><span class="line"></span><br><span class="line"># 将排序过后的坐标对应的名称展示出来，方便观察理解</span><br><span class="line">boston.feature_names[np.argsort(lin_reg.coef_)]</span><br><span class="line"># 输出：array([&#x27;NOX&#x27;, &#x27;DIS&#x27;, &#x27;PTRATIO&#x27;, &#x27;LSTAT&#x27;, &#x27;CRIM&#x27;, &#x27;INDUS&#x27;, &#x27;AGE&#x27;, &#x27;TAX&#x27;,</span><br><span class="line">       &#x27;B&#x27;, &#x27;ZN&#x27;, &#x27;RAD&#x27;, &#x27;CHAS&#x27;, &#x27;RM&#x27;], dtype=&#x27;&lt;U7&#x27;)</span><br></pre></td></tr></table></figure></div>

<p>RM对应的是房间数，是正相关最大的特征，也就是说房间数越多，房价越高，这是很合理的<br>NOX对应的是一氧化氮浓度，也就是说一氧化氮浓度越低，房价越低，这也是非常合理的<br>由此说明，我们的线性回归具有可解释性，我们可以在对研究一个模型的时候，可以先用线性回归模型看一下，然后根据感性的认识去直观的判断一下是否符合我们的语气</p>
<h2 id="6-2-总结"><a href="#6-2-总结" class="headerlink" title="6.2 总结"></a>6.2 总结</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-207d239d640630b5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="6.2-1"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-e3a2b28f8657e2b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="6.2-2"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-57f8e00af3e5987f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="6.2-3"
                ><br><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://upload-images.jianshu.io/upload_images/7220971-3ae395d5fb12edd7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"
                      alt="6.2-4"
                ></p>

            </div>

            
                <div class="post-copyright-info">
                    <div class="article-copyright-info-container">
    <ul>
        <li>Post title：线性回归算法</li>
        <li>Post author：chen</li>
        <li>Create time：2022-12-13 20:38:52</li>
        <li>
            Post link：https://cmvaxx.github.io/2022/12/13/线性回归算法/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

                </div>
            

            

            

            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <div style="font-size: 1.3rem;margin-top: 0; margin-bottom: 0.8rem; transition-duration: 0.1s;"><i class="fa-solid fa-list"></i> <strong>Contents</strong></div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E7%AE%80%E4%BB%8B"><span class="nav-text">1.线性回归算法简介</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%A0%B7%E6%9C%AC%E7%89%B9%E5%BE%81%E5%8F%AA%E6%9C%89%E4%B8%80%E4%B8%AA%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98%EF%BC%8C%E4%B8%BA%E7%AE%80%E5%8D%95%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%8C%E5%A6%82%E6%88%BF%E5%B1%8B%E4%BB%B7%E6%A0%BC-%E6%88%BF%E5%B1%8B%E9%9D%A2%E7%A7%AF"><span class="nav-text">样本特征只有一个的线性回归问题，为简单线性回归，如房屋价格-房屋面积</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%80%9A%E8%BF%87%E4%B8%8A%E9%9D%A2%E7%9A%84%E6%8E%A8%E5%AF%BC%EF%BC%8C%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E5%BD%92%E7%BA%B3%E5%87%BA%E4%B8%80%E7%B1%BB%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF%EF%BC%8C%E5%A6%82%E4%B8%8B%E5%9B%BE%EF%BC%9B%E5%85%B6%E4%B8%AD%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%98%AF%E8%AE%A1%E7%AE%97%E6%9C%9F%E6%9C%9B%E5%80%BC%E5%92%8C%E9%A2%84%E6%B5%8B%E5%80%BC%E7%9A%84%E5%B7%AE%E5%80%BC%EF%BC%8C%E6%9C%9F%E6%9C%9B%E5%85%B6%E5%B7%AE%E5%80%BC%EF%BC%88%E4%B9%9F%E5%B0%B1%E6%98%AF%E6%8D%9F%E5%A4%B1%EF%BC%89%E8%B6%8A%E6%9D%A5%E8%B6%8A%E5%B0%8F%EF%BC%8C%E8%80%8C%E6%95%88%E7%94%A8%E5%87%BD%E6%95%B0%E5%88%99%E6%98%AF%E6%8F%8F%E8%BF%B0%E6%8B%9F%E5%90%88%E5%BA%A6%EF%BC%8C%E6%9C%9F%E6%9C%9B%E5%A5%91%E5%90%88%E5%BA%A6%E8%B6%8A%E6%9D%A5%E8%B6%8A%E5%A5%BD"><span class="nav-text">通过上面的推导，我们可以归纳出一类机器学习算法的基本思路，如下图；其中损失函数是计算期望值和预测值的差值，期望其差值（也就是损失）越来越小，而效用函数则是描述拟合度，期望契合度越来越好</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-text"></span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-%E7%AE%80%E5%8D%95%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-text">2.简单线性回归的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-for%E5%BE%AA%E7%8E%AF%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0"><span class="nav-text">2.1 for循环方式实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0"><span class="nav-text">实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#a-b%E5%85%AC%E5%BC%8F"><span class="nav-text">a,b公式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95"><span class="nav-text">测试</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AE%80%E5%8D%95%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%80%E4%B8%AA%E8%AE%AD%E7%BB%83%E9%9B%86%E5%B9%B6%E6%8F%8F%E7%BB%98"><span class="nav-text">简单自定义一个训练集并描绘</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E6%88%91%E4%BB%AC%E8%87%AA%E5%B7%B1%E7%9A%84SimpleLinearRegression1"><span class="nav-text">使用我们自己的SimpleLinearRegression1</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-%E5%90%91%E9%87%8F%E5%8C%96"><span class="nav-text">2.2 向量化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E5%8C%96%E6%94%B9%E8%BF%9Bnum-d%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95"><span class="nav-text">向量化改进num,d的计算方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E5%8C%96%E5%AE%9E%E7%8E%B0%E7%9A%84%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95"><span class="nav-text">向量化实现的性能测试</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-%E8%A1%A1%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95%E7%9A%84%E6%8C%87%E6%A0%87"><span class="nav-text">3.衡量线性回归算法的指标</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-%E8%A1%A1%E9%87%8F%E6%A0%87%E5%87%86"><span class="nav-text">3.1 衡量标准</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-MSE-RMSE-MAE%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-text">3.2 MSE,RMSE,MAE的实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-%E8%B0%83%E7%94%A8sikit-learn-%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-text">3.3 调用sikit learn 的实现</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-%E6%9C%80%E5%A5%BD%E7%9A%84%E8%A1%A1%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%B3%95%E7%9A%84%E6%8C%87%E6%A0%87-R-Squared"><span class="nav-text">4.最好的衡量线性回归法的指标 R Squared</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RMSE-%E5%92%8C-MAE%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="nav-text">RMSE 和 MAE的局限性</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95-R-Squared%E7%AE%80%E4%BB%8B"><span class="nav-text">4.1 解决办法-R Squared简介</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-1-R-Squared-%E6%84%8F%E4%B9%89"><span class="nav-text">4.1.1 R Squared 意义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-2-%E5%AE%9E%E7%8E%B0"><span class="nav-text">4.1.2 实现</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-text">5.多元线性回归</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%80%E4%BB%8B%E5%92%8C%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E8%A7%A3"><span class="nav-text">5.1 多元线性回归简介和正规方程解</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%AE%9E%E7%8E%B0"><span class="nav-text">4.2 多元线性回归实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E7%9A%84%E6%B5%8B%E8%AF%95"><span class="nav-text">预测波士顿房价的测试</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-scikit-learn%E4%B8%AD%E7%9A%84%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98"><span class="nav-text">4.3 scikit-learn中的回归问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#scikit-learn-%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-text">scikit-learn 中的线性回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kNN-Regressor-%E5%AE%9E%E7%8E%B0%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="nav-text">kNN Regressor 实现线性回归</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E5%8F%AF%E8%A7%A3%E6%80%A7%E5%92%8C%E6%9B%B4%E5%A4%9A%E6%80%9D%E8%80%83"><span class="nav-text">6.线性回归的可解性和更多思考</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#6-1%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7"><span class="nav-text">6.1可解释性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-2-%E6%80%BB%E7%BB%93"><span class="nav-text">6.2 总结</span></a></li></ol></li></ol>
    </div>
</div>
            </div>
        
    </div>
</div>


                

            </div>



        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2022&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">chen</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v0.3.5</a>
        </div>
        
        
    </div>
    <link rel="stylesheet" href="//evan.beee.top/css/waline.css"/>
    <script src="//evan.beee.top/js/waline.js"></script>
    
<link rel="stylesheet" href="/css/regular.min.css">

</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fa-duotone fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>




    
<script src="/js/lazyload.js"></script>



<div class="post-scripts pjax">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            REDEFINE.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            REDEFINE.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            REDEFINE.refresh();
        });
    });
</script>



</body>
</html>
